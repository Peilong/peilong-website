---
title: Course Overview
linktitle: Overview
toc: true
type: docs
date: "2019-05-05T00:00:00+01:00"
draft: false
menu:
  ds420:
    parent: Syllabus
    name: Overview
    weight: 2

# Prev/next pager order (if `docs_section_pager` enabled in `params.toml`)
weight: 2
---

## Course Coverage

This course covers techniques needed to collect, store, analyze, and visualize big data, particularly for applications in machine learning at scale. The MapReduce paradigm will be taught using the popular Hadoop framework. Both batch and real-time analysis of massive quantities of data will be applied to machine learning problems such as clustering, regression, and classification. Although the relational database model will be discussed, NoSQL models will have primary focus.


## Student Learning Outcomes

By the end of the course, the successful students will be able to:

*	(Hadoop Ecosystem) Design distributed systems that manage "big data" using Hadoop and related technologies in the Hadoop Ecosystem.
* (Scalability) Use HDFS and MapReduce for storing and analyzing data at scale.
*	(Programmability) Use Pig and Spark to create scripts to process data on a Hadoop cluster in more complex and programmable ways.
*	(Databases) Analyze relational data using Hive and MySQL, and analyze non-relational data using HBase and MongoDB. Learn to choose an appropriate data storage technology for your application
*	(Machine Learning) Deploy machine learning models at scale to process distributed big data using Spark MLlib.
*	(Management) Understand how Hadoop clusters are managed by Big Data Framework Managers like YARN, Mesos, Zookeeper and Oozie, etc.
*	(Real-time Analysis) Publish data to computing clusters using Kafka and Flume. Consume streaming data using Spark Streaming and Storm. 
